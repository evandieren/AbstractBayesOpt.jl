<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Public API · AbstractBayesOpt.jl</title><meta name="title" content="Public API · AbstractBayesOpt.jl"/><meta property="og:title" content="Public API · AbstractBayesOpt.jl"/><meta property="twitter:title" content="Public API · AbstractBayesOpt.jl"/><meta name="description" content="Documentation for AbstractBayesOpt.jl."/><meta property="og:description" content="Documentation for AbstractBayesOpt.jl."/><meta property="twitter:description" content="Documentation for AbstractBayesOpt.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">AbstractBayesOpt.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Public API</a><ul class="internal"><li><a class="tocitem" href="#Bayesian-Optimisation-loop"><span>Bayesian Optimisation loop</span></a></li><li><a class="tocitem" href="#Abstract-Interface"><span>Abstract Interface</span></a></li><li><a class="tocitem" href="#Surrogates"><span>Surrogates</span></a></li><li><a class="tocitem" href="#Acquisition-Functions"><span>Acquisition Functions</span></a></li><li><a class="tocitem" href="#Domains"><span>Domains</span></a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/1D_BO/">1D Bayesian Optimisation</a></li><li><a class="tocitem" href="../tutorials/2D_BO/">2D Bayesian Optimisation</a></li><li><a class="tocitem" href="../tutorials/acq_funcs_comparison/">1D Acquisition Function Comparison</a></li><li><a class="tocitem" href="../tutorials/hyperparams_comparison/">Hyperparameter &amp; Standardisation Comparison</a></li><li><a class="tocitem" href="../tutorials/nlml_landscape_visualization/">Log Likelihood Landscape Visualisation</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Public API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Public API</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/evandieren/AbstractBayesOpt.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/main/docs/src/reference.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Reference-(Public-API)"><a class="docs-heading-anchor" href="#Reference-(Public-API)">Reference (Public API)</a><a id="Reference-(Public-API)-1"></a><a class="docs-heading-anchor-permalink" href="#Reference-(Public-API)" title="Permalink"></a></h1><p>This section documents the exported functions, types, etc from <strong>AbstractBayesOpt.jl</strong>.</p><hr/><h2 id="Bayesian-Optimisation-loop"><a class="docs-heading-anchor" href="#Bayesian-Optimisation-loop">Bayesian Optimisation loop</a><a id="Bayesian-Optimisation-loop-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-Optimisation-loop" title="Permalink"></a></h2><article><details class="docstring"><summary id="AbstractBayesOpt.BOStruct"><a class="docstring-binding" href="#AbstractBayesOpt.BOStruct"><code>AbstractBayesOpt.BOStruct</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">BOStruct{F,M&lt;:AbstractSurrogate,A&lt;:AbstractAcquisition,D&lt;:AbstractDomain,X,Y,T}(
    func::F,
    acq::A,
    model::M,
    domain::D,
    xs::Vector{X},
    ys::Vector{Y},
    ys_non_std::Vector{Y},
    max_iter::Int,
    iter::Int,
    noise::T,
    flag::Bool,
)</code></pre><p>A structure to hold all components of the Bayesian Optimization problem.</p><p>Attributes:</p><ul><li><code>func::F</code>: The target function to be optimized.</li><li><code>acq::A</code>: The acquisition function guiding the optimization.</li><li><code>model::M</code>: The surrogate model (e.g., Gaussian Process).</li><li><code>domain::D</code>: The domain over which to optimize.</li><li><code>xs::Vector{X}</code>: A vector of input training points.</li><li><code>ys::Vector{Y}</code>: A vector of corresponding output training values.</li><li><code>ys_non_std::Vector{Y}</code>: A vector of output training values before standardization.</li><li><code>max_iter::Int</code>: Maximum number of iterations for the optimization.</li><li><code>iter::Int</code>: Current iteration number.</li><li><code>noise::T</code>: Noise level in the observations.</li><li><code>flag::Bool</code>: A flag to indicate if the optimization should stop due to issues like   ill-conditioning.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/bayesian_opt.jl#L7-L37">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.optimize"><a class="docstring-binding" href="#AbstractBayesOpt.optimize"><code>AbstractBayesOpt.optimize</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">optimize(
    BO::BOStruct;
    standardize::Union{String,Nothing}=&quot;mean_scale&quot;,
    hyper_params::Union{String,Nothing}=&quot;all&quot;,
    num_restarts_HP::Int=1,
)</code></pre><p>This function implements the EGO framework:     While some criterion is not met,         (1) optimize the acquisition function to obtain the new best candidate,         (2) query the target function f,         (3) update the GP and the overall optimization state.     returns best found solution.</p><p>Arguments:</p><ul><li><code>BO::BOStruct</code>: The Bayesian Optimization structure.</li><li><code>standardize</code>: Specifies how to standardize the outputs.<ul><li>If &quot;mean_scale&quot;, standardize by removing mean and scaling by std.</li><li>If &quot;scale_only&quot;, only scale the outputs without centering (in case we set a non-zero mean function with empirical mean).</li><li>If &quot;mean_only&quot;, only remove the mean without scaling.</li><li>If nothing, do not standardize the outputs.</li></ul></li><li><code>hyper_params</code>: Specifies how to handle hyperparameters.<ul><li>If &quot;all&quot;, re-optimize hyperparameters every 10 iterations.</li><li>If &quot;length<em>scale</em>only&quot;, only optimize the lengthscale.</li><li>If nothing, do not re-optimize hyperparameters.</li></ul></li><li><code>num_restarts_HP::Int</code>: Number of random restarts for hyperparameter optimization.</li></ul><p>returns:</p><ul><li><code>BO::BOStruct</code>: The updated Bayesian Optimization problem after optimization.</li><li><code>acqf_list::Vector</code>: List of acquisition function values at each iteration.</li><li><code>standard_params::Tuple</code>: Tuple containing the mean and standard deviation used for standardization</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/bayesian_opt.jl#L330-L363">source</a></div></details></article><h2 id="Abstract-Interface"><a class="docs-heading-anchor" href="#Abstract-Interface">Abstract Interface</a><a id="Abstract-Interface-1"></a><a class="docs-heading-anchor-permalink" href="#Abstract-Interface" title="Permalink"></a></h2><article><details class="docstring"><summary id="AbstractBayesOpt.AbstractAcquisition"><a class="docstring-binding" href="#AbstractBayesOpt.AbstractAcquisition"><code>AbstractBayesOpt.AbstractAcquisition</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">AbstractAcquisition</code></pre><p>Abstract type for acquisition functions used in Bayesian optimization.</p><p>Concrete implementation should subtype this and implement the following methods:</p><ul><li><code>(acq::AbstractAcquisition)(surrogate::AbstractSurrogate, x::AbstractVector)</code>:   Evaluate the acquisition function at point <code>x</code> using the surrogate model.    This should also work for a single real input <code>x::Real</code> if working in 1D, in which case it is treated as a one-dimensional input vector. via the abstract method defined below.</li><li><code>update(acq::AbstractAcquisition, ys::AbstractVector, model::AbstractSurrogate)</code>:   Update the acquisition function with new observations <code>ys</code> and the current surrogate model.</li><li><code>Base.copy(acq::AbstractAcquisition)</code>:   Create a copy of the acquisition function.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/abstract.jl#L35-L48">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.AbstractDomain"><a class="docstring-binding" href="#AbstractBayesOpt.AbstractDomain"><code>AbstractBayesOpt.AbstractDomain</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">AbstractDomain</code></pre><p>An abstract type for defining the domain over which the optimization is performed.</p><p>Concrete implementations should subtype this and define the necessary properties:</p><ul><li><code>lower</code>: The lower bounds of the domain.</li><li><code>upper</code>: The upper bounds of the domain.</li></ul><p>as well as creating its constructor.</p><p>Other methods can be added as needed depending on the use case.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/abstract.jl#L71-L83">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.AbstractSurrogate"><a class="docstring-binding" href="#AbstractBayesOpt.AbstractSurrogate"><code>AbstractBayesOpt.AbstractSurrogate</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">AbstractSurrogate</code></pre><p>Abstract type for surrogate models used in Bayesian optimization.</p><p>Concrete implementation should subtype this and implement the following methods:</p><ul><li><code>update(model::AbstractSurrogate, xs::AbstractVector, ys::AbstractVector)</code>:   Update the surrogate model with new data points <code>xs</code> and corresponding observations <code>ys</code>.</li><li><code>posterior_mean(surrogate::AbstractSurrogate, x::AbstractVector)</code>:   Compute the posterior mean of the surrogate model at point <code>x</code>.</li><li><code>posterior_var(surrogate::AbstractSurrogate, x::AbstractVector)</code>:   Compute the posterior variance of the surrogate model at point <code>x</code>.</li><li><code>nlml(surrogate::AbstractSurrogate, params::AbstractVector, xs::AbstractVector, ys::AbstractVector)</code>:   Compute the negative log marginal likelihood of the surrogate model given hyperparameters <code>params</code>, input data <code>xs</code>, and observations <code>ys</code>.</li></ul><p>If you wish to standardize the outputs, you can also implement:</p><ul><li><code>std_y(model::AbstractSurrogate)</code>:   Get the standard deviation used for standardizing the outputs in the surrogate model.</li><li><code>get_mean_std(model::AbstractSurrogate)</code>:   Get the mean and standard deviation used for standardizing the outputs in the surrogate model.</li></ul><p>Other methods can be added as needed depending on the use case, and we refer to the impelementations of <a href="#AbstractBayesOpt.StandardGP"><code>StandardGP</code></a> and <a href="#AbstractBayesOpt.GradientGP"><code>GradientGP</code></a> for examples.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/abstract.jl#L10-L32">source</a></div></details></article><h2 id="Surrogates"><a class="docs-heading-anchor" href="#Surrogates">Surrogates</a><a id="Surrogates-1"></a><a class="docs-heading-anchor-permalink" href="#Surrogates" title="Permalink"></a></h2><article><details class="docstring"><summary id="AbstractBayesOpt.StandardGP"><a class="docstring-binding" href="#AbstractBayesOpt.StandardGP"><code>AbstractBayesOpt.StandardGP</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">StandardGP{T}(gp::AbstractGPs.GP, noise_var::T, gpx::Union{Nothing,AbstractGPs.PosteriorGP}) &lt;: AbstractSurrogate</code></pre><p>Implementation of the Abstract structures for the standard GP.</p><p>Attributes:</p><ul><li><code>gp::AbstractGPs.GP</code>: The underlying Gaussian Process model.</li><li><code>noise_var::T</code>: The noise variance of the observations.</li><li><code>gpx::Union{Nothing,AbstractGPs.PosteriorGP}</code>: The posterior GP after conditioning on data, <code>nothing</code> if not conditioned yet.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/StandardGP.jl#L1-L10">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.GradientGP"><a class="docstring-binding" href="#AbstractBayesOpt.GradientGP"><code>AbstractBayesOpt.GradientGP</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">struct GradientGP{T, G&lt;:AbstractGPs.GP} &lt;: AbstractSurrogate</code></pre><p>Gradient-enhanced Gaussian Process surrogate model.</p><p>Attributes:</p><ul><li><code>gp::G</code>: The underlying Gaussian Process model.</li><li><code>noise_var::T</code>: The noise variance of the observations.</li><li><code>p::Int</code>: The number of outputs (1 for function value + d for gradients).</li><li><code>gpx::Union{Nothing, AbstractGPs.PosteriorGP}</code>: The posterior GP after conditioning on data,   <code>nothing</code> if not conditioned yet.</li></ul><p>Note: <code>gpx</code> is the posterior GP after conditioning on data, nothing if not conditioned yet</p><p>This relies on <code>MOGP</code> from <code>AbstractGPs.jl</code> and <code>KernelFunctions.jl</code>.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L1-L16">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.posterior_mean"><a class="docstring-binding" href="#AbstractBayesOpt.posterior_mean"><code>AbstractBayesOpt.posterior_mean</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">posterior_mean(model::StandardGP, x::X) where {X}</code></pre><p>Compute the posterior mean of the GP at a new input point.</p><p>Arguments:</p><ul><li><code>model::StandardGP</code>: The GP model.</li><li><code>x::X</code>: A new input point where the prediction is to be made.</li></ul><p>returns:</p><ul><li><code>mean</code>: The posterior mean prediction at the input point.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/StandardGP.jl#L317-L328">source</a></div><div><pre><code class="language-julia hljs">posterior_mean(model::StandardGP, x::AbstractVector)</code></pre><p>Compute the posterior mean of the GP at set of new input points.</p><p>Arguments:</p><ul><li><code>model::StandardGP</code>: The GP model.</li><li><code>x::AbstractVector</code>: A vector of new input points where predictions are to be made.</li></ul><p>returns:</p><ul><li><code>mean</code>: The posterior mean predictions at the input points.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/StandardGP.jl#L349-L360">source</a></div><div><pre><code class="language-julia hljs">posterior_mean(model::GradientGP, x)</code></pre><p>Compute the function mean predictions of the GP model at new input points.</p><p>Arguments:</p><ul><li><code>model::GradientGP</code>: The GP model.</li><li><code>x</code>: A vector of new input points where predictions are to be made.</li></ul><p>returns:</p><ul><li><code>mean::Vector</code>: The mean predictions (function value only)</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L973-L984">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.posterior_var"><a class="docstring-binding" href="#AbstractBayesOpt.posterior_var"><code>AbstractBayesOpt.posterior_var</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">posterior_var(model::StandardGP, x::X) where {X}</code></pre><p>Compute the posterior variance of the GP at a new input point.</p><p>Arguments:</p><ul><li><code>model::StandardGP</code>: The GP model.</li><li><code>x::X</code>: A new input point where the prediction is to be made.</li></ul><p>returns:</p><ul><li><code>var</code>: The posterior variance prediction at the input point.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/StandardGP.jl#L333-L344">source</a></div><div><pre><code class="language-julia hljs">posterior_var(model::StandardGP, x::AbstractVector)</code></pre><p>Compute the posterior variance of the GP at set of new input points.</p><p>Arguments:</p><ul><li><code>model::StandardGP</code>: The GP model.</li><li><code>x::AbstractVector</code>: A vector of new input points where predictions are to be made</li></ul><p>returns:</p><ul><li><code>var</code>: The posterior variance predictions at the input points.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/StandardGP.jl#L365-L376">source</a></div><div><pre><code class="language-julia hljs">posterior_var(model::GradientGP, x)</code></pre><p>Compute the function variance predictions of the GP model at new input points.</p><p>Arguments:</p><ul><li><code>model::GradientGP</code>: The GP model.</li><li><code>x</code>: A vector of new input points where predictions are to be made.</li></ul><p>returns:</p><ul><li><code>var::Vector</code>: The variance predictions (function value only)</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L989-L1000">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.nlml"><a class="docstring-binding" href="#AbstractBayesOpt.nlml"><code>AbstractBayesOpt.nlml</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">nlml(model::StandardGP, params, xs::AbstractVector, ys::AbstractVector)</code></pre><p>Compute the negative log marginal likelihood (NLML) of the GP model given hyperparameters.</p><p>Arguments:</p><ul><li><code>model::StandardGP</code>: The GP model.</li><li><code>params</code>: A vector containing the log lengthscale and log scale parameters.</li><li><code>xs::AbstractVector</code>: The input data points.</li><li><code>ys::AbstractVector</code>: The observed function values.</li></ul><p>returns:</p><ul><li>nlml::Float64: The negative log marginal likelihood of the model.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/StandardGP.jl#L85-L98">source</a></div><div><pre><code class="language-julia hljs">nlml(model::GradientGP, params, xs::AbstractVector, ys::AbstractVector)</code></pre><p>Compute the negative log marginal likelihood (NLML) of the GP model given hyperparameters.</p><p>Arguments:</p><ul><li><code>model::GradientGP</code>: The GP model.</li><li><code>params</code>: Parameters containing the log lengthscale and log scale.</li><li><code>xs::AbstractVector</code>: The input data points.</li><li><code>ys::AbstractVector</code>: The observed function values and gradients.</li></ul><p>returns:</p><ul><li>nlml::Float64: The negative log marginal likelihood of the model.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L670-L683">source</a></div></details></article><h3 id="Kernels"><a class="docs-heading-anchor" href="#Kernels">Kernels</a><a id="Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Kernels" title="Permalink"></a></h3><article><details class="docstring"><summary id="AbstractBayesOpt.ApproxMatern52Kernel"><a class="docstring-binding" href="#AbstractBayesOpt.ApproxMatern52Kernel"><code>AbstractBayesOpt.ApproxMatern52Kernel</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">ApproxMatern52Kernel{M}(metric::M) &lt;: KernelFunctions.SimpleKernel</code></pre><p>Approximate Matern 5/2 kernel using a second-order Taylor expansion around d=0.</p><p>Attributes:</p><ul><li><code>metric</code>: The distance metric to be used, defaults to squared Euclidean distance.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L44-L51">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.ApproxMatern72Kernel"><a class="docstring-binding" href="#AbstractBayesOpt.ApproxMatern72Kernel"><code>AbstractBayesOpt.ApproxMatern72Kernel</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">ApproxMatern72Kernel{M}(metric::M) &lt;: KernelFunctions.SimpleKernel</code></pre><p>Approximate Matern 7/2 kernel using a second-order Taylor expansion around d=0.</p><p>Attributes:</p><ul><li><code>metric</code>: The distance metric to be used, defaults to squared Euclidean distance.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L270-L277">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.ADMatern52Kernel"><a class="docstring-binding" href="#AbstractBayesOpt.ADMatern52Kernel"><code>AbstractBayesOpt.ADMatern52Kernel</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">ADMatern52Kernel{M} &lt;: KernelFunctions.SimpleKernel</code></pre><p>Matern 5/2 kernel with custom differentiation rules for gradient computations.</p><p>Attributes:</p><ul><li><code>metric</code>: The distance metric to be used, defaults to squared Euclidean distance.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L125-L132">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.ADMatern72Kernel"><a class="docstring-binding" href="#AbstractBayesOpt.ADMatern72Kernel"><code>AbstractBayesOpt.ADMatern72Kernel</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">ADMatern72Kernel{M} &lt;: KernelFunctions.SimpleKernel</code></pre><p>Matern 7/2 kernel with custom differentiation rules for gradient computations.</p><p>Attributes:</p><ul><li><code>metric</code>: The distance metric to be used, defaults to squared Euclidean distance.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L348-L355">source</a></div></details></article><h3 id="GradientGP-related-functions"><a class="docs-heading-anchor" href="#GradientGP-related-functions">GradientGP-related functions</a><a id="GradientGP-related-functions-1"></a><a class="docs-heading-anchor-permalink" href="#GradientGP-related-functions" title="Permalink"></a></h3><article><details class="docstring"><summary id="AbstractBayesOpt.gradConstMean"><a class="docstring-binding" href="#AbstractBayesOpt.gradConstMean"><code>AbstractBayesOpt.gradConstMean</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">gradConstMean{V}(c::V)</code></pre><p>Custom mean function for the GradientGP model. Returns a constant per-output mean across MO inputs (function value + gradients). The first element corresponds to the function value, the following ones to the gradient outputs.</p><p>Use <code>gradConstMean([μ; zeros(d)])</code> to set a constant prior mean <code>μ</code> for the function value and zero for the gradients.</p><p>Attributes:</p><ul><li><code>c::V</code>: A vector of constants for each output (function value + gradients).</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L492-L504">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.gradKernel"><a class="docstring-binding" href="#AbstractBayesOpt.gradKernel"><code>AbstractBayesOpt.gradKernel</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">gradKernel{K}(base_kernel::K) &lt;: MOKernel</code></pre><p>Custom kernel function for the GradientGP model that handles both function values and gradients.</p><p>Arguments:</p><ul><li><code>base_kernel::KernelFunctions.Kernel</code>: The base kernel function to be used.</li></ul><p>returns:</p><ul><li><code>gradKernel</code>: An instance of the custom gradient kernel function.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L533-L543">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.posterior_grad_mean"><a class="docstring-binding" href="#AbstractBayesOpt.posterior_grad_mean"><code>AbstractBayesOpt.posterior_grad_mean</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">posterior_grad_mean(model::GradientGP, x)</code></pre><p>Compute the mean predictions of the GP model at new input points, including gradients.</p><p>Arguments:</p><ul><li><code>model::GradientGP</code>: The GP model.</li><li><code>x</code>: A vector of new input points where predictions are to be made.</li></ul><p>returns:</p><ul><li><code>mean::Vector</code>: The mean predictions</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L924-L935">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.posterior_grad_var"><a class="docstring-binding" href="#AbstractBayesOpt.posterior_grad_var"><code>AbstractBayesOpt.posterior_grad_var</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">posterior_grad_var(model::GradientGP, x)</code></pre><p>Compute the variance predictions of the GP model at new input points, including gradients.</p><p>Arguments:</p><ul><li><code>model::GradientGP</code>: The GP model.</li><li><code>x</code>: A vector of new input points where predictions are to be made.</li></ul><p>returns:</p><ul><li><code>var::Vector</code>: The variance predictions</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L941-L952">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.posterior_grad_cov"><a class="docstring-binding" href="#AbstractBayesOpt.posterior_grad_cov"><code>AbstractBayesOpt.posterior_grad_cov</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">posterior_grad_cov(model::GradientGP, x)</code></pre><p>Compute the covariance matrix of the GP model at new input points, including gradients.</p><p>Arguments:</p><ul><li><code>model::GradientGP</code>: The GP model.</li><li><code>x</code>: A vector of new input points where predictions are to be made.</li></ul><p>returns:</p><ul><li><code>cov::Matrix</code>: The covariance matrix of the predictions</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/surrogates/GradientGP.jl#L957-L968">source</a></div></details></article><h2 id="Acquisition-Functions"><a class="docs-heading-anchor" href="#Acquisition-Functions">Acquisition Functions</a><a id="Acquisition-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Acquisition-Functions" title="Permalink"></a></h2><article><details class="docstring"><summary id="AbstractBayesOpt.EnsembleAcquisition"><a class="docstring-binding" href="#AbstractBayesOpt.EnsembleAcquisition"><code>AbstractBayesOpt.EnsembleAcquisition</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">EnsembleAcquisition(weights::Vector{Float64}, acqs::Vector{AbstractAcquisition}) &lt;: AbstractAcquisition</code></pre><p>An ensemble acquisition function combines multiple acquisition functions, each weighted by a specified factor,</p><p>Attributes:</p><ul><li><code>weights::Vector{Float64}</code>: A vector of non-negative weights for each acquisition function. The weights are normalized to sum to 1.</li><li><code>acquisitions::Vector{AbstractAcquisition}</code>: A vector of acquisition functions to be combined.</li></ul><p>Remark: All weights must be non-negative.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/acquisition_functions/EnsembleAcq.jl#L1-L11">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.ExpectedImprovement"><a class="docstring-binding" href="#AbstractBayesOpt.ExpectedImprovement"><code>AbstractBayesOpt.ExpectedImprovement</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">ExpectedImprovement{Y}(ξ::Y, best_y::Y) &lt;: AbstractAcquisition</code></pre><p>Expected Improvement acquisition function.</p><p>Attributes:</p><ul><li><code>ξ::Y</code>: Exploration parameter</li><li><code>best_y::Y</code>: Best observed objective value</li></ul><p>References: <a href="https://link.springer.com/article/10.1023/A:1008306431147">Jones et al., 1998</a></p><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/acquisition_functions/ExpectedImprovement.jl#L1-L12">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.GradientNormUCB"><a class="docstring-binding" href="#AbstractBayesOpt.GradientNormUCB"><code>AbstractBayesOpt.GradientNormUCB</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">GradientNormUCB{Y}(β::Y) &lt;: AbstractAcquisition</code></pre><p>Acquisition function implementing the Squared 2-norm of the gradient with Upper Confidence Bound (UCB) exploration strategy.</p><p>Attributes:</p><ul><li><code>β::Y</code>: Exploration-exploitation balance parameter</li></ul><p>References:     Derived by Van Dieren, E. but open to previous references if existing.     Originally proposed by <a href="https://www.sciencedirect.com/science/article/pii/S2405896323020487">Makrygiorgos et al., 2023</a> but adapted to the squared 2-norm of the gradient.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/acquisition_functions/gradNormUCB.jl#L1-L12">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.ProbabilityImprovement"><a class="docstring-binding" href="#AbstractBayesOpt.ProbabilityImprovement"><code>AbstractBayesOpt.ProbabilityImprovement</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">ProbabilityImprovement{Y}(ξ::Y, best_y::Y) &lt;: AbstractAcquisition</code></pre><p>Attributes:</p><ul><li><code>ξ::Y</code>: Exploration parameter</li><li><code>best_y::Y</code>: Best observed objective value</li></ul><p>References: <a href="https://asmedigitalcollection.asme.org/fluidsengineering/article/86/1/97/392213/A-New-Method-of-Locating-the-Maximum-Point-of-an">Kushner, 1964</a></p><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/acquisition_functions/ProbabilityImprovement.jl#L1-L10">source</a></div></details></article><article><details class="docstring"><summary id="AbstractBayesOpt.UpperConfidenceBound"><a class="docstring-binding" href="#AbstractBayesOpt.UpperConfidenceBound"><code>AbstractBayesOpt.UpperConfidenceBound</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">UpperConfidenceBound{Y}(β::Y) &lt;: AbstractAcquisition</code></pre><p>Upper Confidence Bound (UCB) acquisition function.</p><p>Attributes:</p><ul><li><code>β::Y</code>: Exploration-exploitation balance parameter</li></ul><p>References: <a href="https://ieeexplore.ieee.org/document/6138914">Srinivas et al., 2012</a></p><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/acquisition_functions/UpperConfidenceBound.jl#L1-L11">source</a></div></details></article><h2 id="Domains"><a class="docs-heading-anchor" href="#Domains">Domains</a><a id="Domains-1"></a><a class="docs-heading-anchor-permalink" href="#Domains" title="Permalink"></a></h2><h3 id="Continuous-domain"><a class="docs-heading-anchor" href="#Continuous-domain">Continuous domain</a><a id="Continuous-domain-1"></a><a class="docs-heading-anchor-permalink" href="#Continuous-domain" title="Permalink"></a></h3><article><details class="docstring"><summary id="AbstractBayesOpt.ContinuousDomain"><a class="docstring-binding" href="#AbstractBayesOpt.ContinuousDomain"><code>AbstractBayesOpt.ContinuousDomain</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">ContinuousDomain(lower::Vector{Float64}, upper::Vector{Float64}, bounds::Vector{Tuple{Float64,Float64}}) &lt;: AbstractDomain</code></pre><p>A concrete implementation of <code>AbstractDomain</code> for continuous domains.</p><p>Attributes:</p><ul><li><code>lower::Vector{Float64}</code>: The lower bounds of the domain.</li><li><code>upper::Vector{Float64}</code>: The upper bounds of the domain.</li><li><code>bounds::Vector{Tuple{Float64,Float64}}</code>: A vector of tuples representing the (lower, upper) bounds for each dimension.</li></ul><p>Constructor:</p><ul><li><code>ContinuousDomain(lower::Vector{Float64}, upper::Vector{Float64})</code>:   Creates a <code>ContinuousDomain</code> instance given lower and upper bounds.   Performs sanity checks to ensure the bounds are valid.</li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/evandieren/AbstractBayesOpt.jl/blob/b29b835e19fce189c31f058823b9eeb417590254/src/domains/ContinuousDomain.jl#L1-L15">source</a></div></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../tutorials/1D_BO/">1D Bayesian Optimisation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.0 on <span class="colophon-date" title="Wednesday 19 November 2025 11:47">Wednesday 19 November 2025</span>. Using Julia version 1.12.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body><div data-docstringscollapsed="true"></div></html>
